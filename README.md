# wav2lip_288x288 introduction
This is a project about talking faces. We use288X288 sized facial images for training, which can generate720p, 1080p, 2k,  human videos.
We have done the following work:
1. Add video cutting codes.
2. Add filelists to generate code.
3. Trained 600 people, 30 hours, and over 30000 pieces of data.
4. Open sourced the checkpoint for a discriminator with 150000 steps and a val_rass of 0.28.
5. Open sourced a checkpoint for a generator with 360000 steps and a val_rass of 0.25.
6. Dear friends, you can load pre training weights for easy subsequent training.


# wav2lip-288x288 Project situation
<p align='center'>
  <b>
    <a href="https://www.bilibili.com/video/BV1zK421v7wh/?vd_source=7720ff9e037156b51374d14ee8f76b51">Video </a>
    | 
    <a href="https://github.com/langzizhixin">Project Page</a>
    |
    <a href="https://github.com/langzizhixin/wav2lip-576x576">Code</a> 
  </b>
</p> 
  <p align='center'>  
    <img src='576x576-CorrespondingVideo.jpg' width='1000'/>
  </p>

# wav2lip_288x288
# wav2lip_384x384
# wav2lip_576x576 
# Release Plan
For the wav2lip series, we will continue to train and release higher definition weights in the future.
The plan is as follows:
Pre training checkpoints for wav2lip_384x384 will be released in February 2025.
Pre training checkpoints for wav2lip_576x576 or 512x512 will be released in June 2025.


# author
Project  made by Lu Rui from Langzizhixin Technology company in Chengdu, China, 2025.1.1


# Citing
Thank you for their wonderful work.

https://github.com/primepake/wav2lip_288x288
https://github.com/Rudrabha/Wav2Lip
Thank the above two authors, Thank you for their wonderful work.
